{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UbJrC7Fq43T"
      },
      "source": [
        "「 Autograd（自動微分）」\n",
        "===============================================================\n",
        "【原題】Autograd: Automatic Differentiation\n",
        "\n",
        "【原著】[Soumith Chintala](http://soumith.ch/)\n",
        "\n",
        "【元URL】https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\n",
        "\n",
        "【翻訳】電通国際情報サービスISID AIトランスフォーメーションセンター　徳原　光\n",
        "\n",
        "【日付】2020年10月27日\n",
        "\n",
        "【チュトーリアル概要】\n",
        "\n",
        "PyTorchによるニューラルネットワークの学習において、重要な概念でありパッケージでもあるautogradの機能、そしてその動作内容について解説します。\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-Amyp7mS-Uc"
      },
      "source": [
        "Autograd: 自動微分\n",
        "=================\n",
        "PyTorchによるニューラルネットワーク構築の土台となっているのが、autograd（自動微分）パッケージです。\n",
        "\n",
        "このパッケージの概要をざっくりと確認し、本チュートリアルシリーズで初めてとなるニューラルネットワークの訓練を体験しましょう。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqM3lrlxsJVD"
      },
      "source": [
        "autogradパッケージはTensorの操作に対する自動微分機能を提供します。\n",
        "\n",
        "Tensor操作に基づく自動微分はdefine-by-runフレームワークであり、ユーザーが実行したコードに対応して誤差逆伝搬が定義され、すべてのイテレーションの計算で異なる結果を生み出します。\n",
        "\n",
        "ここからは、いくつかの実例を通してこの機能を簡単に見ていきましょう。\n",
        "\n",
        "<br>\n",
        "\n",
        "（日本語訳注：define-by-runはデータをニューラルネットワークに流しながら、モデルの構築を行っていく手法を指します。一方でdefine-and-runは先に誤差逆伝搬の形を実行する前に構築します。）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJRlOUfrPezQ"
      },
      "source": [
        "\n",
        "テンソル（Tensor）\n",
        "==================\n",
        "``torch.Tensor``はパッケージの中心的なクラスです。\n",
        "\n",
        "``.requires_grad``属性が``True``に設定された場合、autogradパッケージによってすべての操作が追跡され、演算が終了した際は``.backward()``を呼び出すことで、すべての操作に対する勾配が自動的に計算されます。\n",
        "\n",
        "このTensorに対する勾配は``.grad``属性に蓄積されていきます。\n",
        "\n",
        "追跡履歴からTensorを切り離して、追跡を停止する場合は、 ``.detach()``を呼び出します。\n",
        "\n",
        "これにより、その後の演算ではこのこのTensorは追跡されないように設定可能です。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHM2R7Btsda3"
      },
      "source": [
        "``with torch.no_grad():``でコードをブロックにまとめることで、追跡履歴（とメモリの利用）を省略することもできます。\n",
        "\n",
        "これはモデルを評価する際、``requires_grad=True``により学習可能なパラメータを持っているが、勾配の計算は必要ない場合に特に有効です。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0NiMGxlOe4x"
      },
      "source": [
        "そしてもう一つ、自動微分の実行に非常に重要なクラスに``Function``があります。\n",
        "\n",
        "``Tensor``と``Function``は 相互に接続し、非巡回グラフで完全な計算履歴を記録しています。\n",
        "\n",
        "各Tensorは、そのTensorを作成した``Function`` を参照する``.grad_fn``属性を持ちます（ユーザーが直接定義したテンソルの場合は``grad_fn is None``となります）。\n",
        "\n",
        "導関数を算出する場合は、``Tensor``が持つ関数``.backward()``を呼び出します。\n",
        "\n",
        "``Tensor``がスカラー（すなわち、要素数が1つだけ）の場合、``.backward()``に引数を指定する必要はありません。しかし、テンソルが複数要素を持つ場合は、Tensorと同じ大きさのTensorを``gradient``の引数に指定する必要があります。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KEFlGoOZAMR7"
      },
      "outputs": [],
      "source": [
        " %matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IUxlqaEXPezR"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugx1PnHBPezU"
      },
      "source": [
        "Tensorを作成し、``requires_grad=True``と指定することによって演算を追跡してみましょう。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmN6W3fVPezU",
        "outputId": "6787bbbc-9e30-44ec-d48f-aa67fe753391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l427YOrPezY"
      },
      "source": [
        "Tensorの計算を実行：\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdDnSkYDPezY",
        "outputId": "d70f17f2-7c88-4d92-f328-be0517f5e0bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "y = x + 2\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk9ssq5QPeza"
      },
      "source": [
        "``y`` は計算結果であり、 計算履歴として``grad_fn``を持っています。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpUz2YwFPezb",
        "outputId": "df89586a-e6e6-4324-b8ca-7dfd621f0b4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<AddBackward0 object at 0x7b859193c6a0>\n"
          ]
        }
      ],
      "source": [
        "print(y.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7-fxhfEPezd"
      },
      "source": [
        "さらに、``y``を用いた計算を実行します：\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjx0OqiHPeze",
        "outputId": "7227f029-3b36-4243-87a1-e26b3578545c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>)\n",
            "out: tensor(27., grad_fn=<MeanBackward0>)\n",
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "z = y * y * 3\n",
        "print(z)\n",
        "out = z.mean()\n",
        "print(\"out:\", out)\n",
        "\n",
        "print(z, out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5_AQV-5Pezh"
      },
      "source": [
        "``.requires_grad_( ... )`` によって既存のTensorの ``requires_grad``フラグを変更することができます。\n",
        "\n",
        "テンソルの作成時に引数で何も指定していない場合は、``requires_grad``はデフォルト値として ``False`` に設定されています。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ2GLGJgPezi",
        "outputId": "5489ead1-8a05-4d37-c2d9-0670daa2350d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1495, -0.7898],\n",
            "        [ 0.4338, -0.3760]])\n",
            "None\n",
            "False\n",
            "True\n",
            "<SumBackward0 object at 0x7b85a82b8c40>\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(2, 2)\n",
        "print(a)\n",
        "a = ((a * 3) / (a - 1))\n",
        "print(a.grad_fn) # requires_gradがtrueではないので、None\n",
        "print(a.requires_grad)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqq783Z1Pezl"
      },
      "source": [
        "勾配（Gradients）\n",
        "==================\n",
        "では、誤差逆伝搬を実行してみましょう。\n",
        "\n",
        "変数``out``はスカラーの値を持っているため, ``out.backward()`` は``out.backward(torch.tensor(1.))``と同じ結果になります。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "V0V_zGPzPezl"
      },
      "outputs": [],
      "source": [
        "out.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiM8cjlDs5Df",
        "outputId": "6f4809c1-5f3c-4f0a-aa18-d3503834391e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(27., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPcj6hy6Pezo"
      },
      "source": [
        "勾配 d(out)/dxを表示。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3VI_KMyPezp",
        "outputId": "e0189ffa-c2be-4155-bf3f-328d8091ac7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ]
        }
      ],
      "source": [
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWCobsqVPezr"
      },
      "source": [
        "結果としてすべての要素が ``4.5``の行列を得たのではないでしょうか。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwoB0GDyQum3"
      },
      "source": [
        "この出力テンソルを“$o$”と記載します。\n",
        "テンソル“$o$”を計算すると、\n",
        "\n",
        "$o = \\frac{1}{4}\\sum_i z_i$\n",
        "\n",
        "$z_i = 3(x_i+2)^2$\n",
        "\n",
        "そして、\n",
        "\n",
        " $z_i\\bigr\\rvert_{x_i=1} = 27$.\n",
        "\n",
        "なので、\n",
        "\n",
        "$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$\n",
        "\n",
        "$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$\n",
        "\n",
        "となります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrBVkBEdPezr"
      },
      "source": [
        "\n",
        "数学的には、ベクトル関数 $\\vec{y}=f(\\vec{x})$において、 $\\vec{x}$に関する$\\vec{y}$ の勾配はヤコビアンと呼ばれています。\n",
        "\n",
        "\\begin{align}J=\\left(\\begin{array}{ccc}\n",
        "   \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\\n",
        "   \\vdots & \\ddots & \\vdots\\\\\n",
        "   \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
        "   \\end{array}\\right)\\end{align}\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mITIyYK1uNSJ"
      },
      "source": [
        "\n",
        "一般的に、 ``torch.autograd`` はベクトルのヤコビアンの積を算出する計算エンジンになります。\n",
        "\n",
        "\n",
        "\n",
        "これは、$v=\\left(\\begin{array}{cccc} v_{1} & v_{2} & \\cdots & v_{m}\\end{array}\\right)^{T}$というベクトルに対して、行列積$v^{T}\\cdot J$を計算することを意味します。\n",
        "\n",
        " もし、 $v$ がスカラー関数の勾配 $l=g\\left(\\vec{y}\\right)$であった場合、\n",
        "$v=\\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial y_{1}} & \\cdots & \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right)^{T}$と表されます。\n",
        "\n",
        "そして連鎖律により、ベクトルのヤコビアンの積は$\\vec{x}$に関する$l$の勾配となるのです。\n",
        "\n",
        "\\begin{align}J^{T}\\cdot v=\\left(\\begin{array}{ccc}\n",
        "   \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{1}}\\\\\n",
        "   \\vdots & \\ddots & \\vdots\\\\\n",
        "   \\frac{\\partial y_{1}}{\\partial x_{n}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
        "   \\end{array}\\right)\\left(\\begin{array}{c}\n",
        "   \\frac{\\partial l}{\\partial y_{1}}\\\\\n",
        "   \\vdots\\\\\n",
        "   \\frac{\\partial l}{\\partial y_{m}}\n",
        "   \\end{array}\\right)=\\left(\\begin{array}{c}\n",
        "   \\frac{\\partial l}{\\partial x_{1}}\\\\\n",
        "   \\vdots\\\\\n",
        "   \\frac{\\partial l}{\\partial x_{n}}\n",
        "   \\end{array}\\right)\\end{align}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5Aq5nvp_C31"
      },
      "source": [
        "( $v^{T}\\cdot J$ は転置の公式から、 $J^{T}\\cdot v$を計算して得られる列ベクトル、と同じ成分の行ベクトルを与えることに注意してください)\n",
        "\n",
        "このベクトルのヤコビアンの積の性質は、スカラ量ではない出力を持つモデルに対して、外部から異なる勾配を追加して計算する際に、非常に有効に利用できます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11kqmutDBxpK"
      },
      "source": [
        "ベクトルのヤコビアンの積の例を見てみましょう"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jObNZxwcPezs",
        "outputId": "e6ae8e5e-fe85-4aa9-dc0a-5c14bd84d2ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.9859, 5.5040, 2.6722], grad_fn=<MulBackward0>)\n",
            "tensor(6.4326)\n",
            "tensor([ 508.3944, 1409.0165,  684.0769], grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "print(y)\n",
        "print(y.data.norm())\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6uh8nEBWYRv"
      },
      "source": [
        "（日本語訳注：関数norm()はノルム≒距離を与えます、引数なしのnorm()は2乗ノルムです。\n",
        "各要素を2乗して足し算し、そのルートを計算します）\n",
        "\n",
        "よって上記では、乱数で発生させたxを2倍、4倍、8倍、・・・とyの3要素の2乗和の平均のルートが1000を超えるまで増加させています。\n",
        "\n",
        "以下の計算結果を参照）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcQGt4PnXPCN",
        "outputId": "eb959614-a208-4c74-8f45-0c08dbfd3512"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1646.7402, grad_fn=<SqrtBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# 日本語訳注\n",
        "torch.sqrt(y[0]*y[0] + y[1]*y[1] + y[2]*y[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mqnhD_ePezu"
      },
      "source": [
        "この場合、 ``y`` はスカラ量ではありません。 ``torch.autograd``\n",
        "では直接ヤコビアンの全要素を計算することはできませんが、ベクトルとヤコビアンの積を計算するだけの場合には、簡単に引数として``backward``にベクトルを与えることで勾配が算出できます。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQA2eq51Pezv",
        "outputId": "014947d9-7418-48a3-8775-7a5c3e1113f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])\n"
          ]
        }
      ],
      "source": [
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
        "y.backward(v)\n",
        "\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFELk6eua6Sp",
        "outputId": "38652578-15ab-43a3-f83f-f81dc317e299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x： tensor([0.9930, 2.7520, 1.3361], requires_grad=True)\n",
            "y： tensor([ 508.3944, 1409.0165,  684.0769], grad_fn=<MulBackward0>)\n",
            "倍数： tensor([512., 512., 512.], grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# 日本語訳注\n",
        "print(\"x：\", x)\n",
        "print(\"y：\", y)\n",
        "scale = y/x\n",
        "print(\"倍数：\", scale)\n",
        "\n",
        "# このセルの出力から何倍して、yを求めたのか分かります。倍数:　の出力部分です。\n",
        "# このセルでは変数sclaeで表しています。\n",
        "# y = scale * x なので、yのxに関する勾配は scaleです。\n",
        "# yの勾配をvに対して計算した結果、xに対して溜まる勾配値がx.gradです。\n",
        "# その値x.grad（上記のセルの出力結果）は、\n",
        "# scaleにv＝[0.1, 1, 0.0001]がかけ算された値となっているはずです。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu8ZOwFOPezy"
      },
      "source": [
        "``with torch.no_grad():``でコードをまとめることで、``.requires_grad=True``となっているTensorの追跡履歴からautogradを停止することができます。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph4dTCdjPez0",
        "outputId": "3fdfda26-1642-420b-93eb-2a89bfc9c1b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "\tprint((x ** 2).requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjNMWxnxFehy"
      },
      "source": [
        "要素が同じTensorを作成した際も、勾配が必要ない場合は``.detach()``を用いることも可能です。\n",
        "\n",
        "（日本語訳注：以下のセルの.eq()はTensorとして値が同じであればTrueを返します。いまは、xとyの要素は3つあるので、その3つに対して求めた結果を.all()でまとめて求めています　[詳細](https://pytorch.org/docs/stable/generated/torch.eq.html)）\n",
        "\n",
        "## 学習したこと\n",
        "tensor.all()は全ての値がTrueの場合はTrueを返す。数値の場合は0以外ならTrueになる。一つでもTrueの場合、Trueを返したい場合はtensor.any()を使用する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzVdQiRZPez2",
        "outputId": "de112c3c-1c19-4c52-d5aa-53d0a74bf6eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n",
            "tensor(True)\n",
            "tensor(True)\n"
          ]
        }
      ],
      "source": [
        "print(x.requires_grad)\n",
        "y = x.detach()\n",
        "print(y.requires_grad)\n",
        "print(x.eq(y).all())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJADPZLdPez5"
      },
      "source": [
        "\n",
        "**補足:**\n",
        "\n",
        "``autograd.Function`` のドキュメントは\n",
        "https://pytorch.org/docs/stable/autograd.html#function\n",
        "を参照してください。\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "1_2_autograd_tutorial_jp.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}