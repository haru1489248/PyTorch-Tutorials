{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haru1489248/PyTorch-Tutorials/blob/main/transformer_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "JvjKw-jAjeuJ"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVl5B4dvjeuK"
      },
      "source": [
        "\n",
        "Sequence-to-Sequence Modeling with nn.Transformer and TorchText\n",
        "===============================================================\n",
        "\n",
        "This is a tutorial on how to train a sequence-to-sequence model\n",
        "that uses the\n",
        "`nn.Transformer <https://pytorch.org/docs/master/nn.html?highlight=nn%20transformer#torch.nn.Transformer>`__ module.\n",
        "\n",
        "PyTorch 1.2 release includes a standard transformer module based on the\n",
        "paper `Attention is All You\n",
        "Need <https://arxiv.org/pdf/1706.03762.pdf>`__. The transformer model\n",
        "has been proved to be superior in quality for many sequence-to-sequence\n",
        "problems while being more parallelizable. The ``nn.Transformer`` module\n",
        "relies entirely on an attention mechanism (another module recently\n",
        "implemented as `nn.MultiheadAttention <https://pytorch.org/docs/master/nn.html?highlight=multiheadattention#torch.nn.MultiheadAttention>`__) to draw global dependencies\n",
        "between input and output. The ``nn.Transformer`` module is now highly\n",
        "modularized such that a single component (like `nn.TransformerEncoder <https://pytorch.org/docs/master/nn.html?highlight=nn%20transformerencoder#torch.nn.TransformerEncoder>`__\n",
        "in this tutorial) can be easily adapted/composed.\n",
        "\n",
        "![](../_static/img/transformer_architecture.jpg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCP-zor7jeuL"
      },
      "source": [
        "Define the model\n",
        "----------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZbZ0EvOjeuL"
      },
      "source": [
        "In this tutorial, we train ``nn.TransformerEncoder`` model on a\n",
        "language modeling task. The language modeling task is to assign a\n",
        "probability for the likelihood of a given word (or a sequence of words)\n",
        "to follow a sequence of words. A sequence of tokens are passed to the embedding\n",
        "layer first, followed by a positional encoding layer to account for the order\n",
        "of the word (see the next paragraph for more details). The\n",
        "``nn.TransformerEncoder`` consists of multiple layers of\n",
        "`nn.TransformerEncoderLayer <https://pytorch.org/docs/master/nn.html?highlight=transformerencoderlayer#torch.nn.TransformerEncoderLayer>`__. Along with the input sequence, a square\n",
        "attention mask is required because the self-attention layers in\n",
        "``nn.TransformerEncoder`` are only allowed to attend the earlier positions in\n",
        "the sequence. For the language modeling task, any tokens on the future\n",
        "positions should be masked. To have the actual words, the output\n",
        "of ``nn.TransformerEncoder`` model is sent to the final Linear\n",
        "layer, which is followed by a log-Softmax function.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "DeWY_o0vjeuL"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "\n",
        "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "        self.model_type = 'Transformer'\n",
        "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        self.ninp = ninp\n",
        "        self.decoder = nn.Linear(ninp, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    # src shape >> (bptt, batch_size)\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.ninp) # (bptt, batch_size, ninp)\n",
        "        src = self.pos_encoder(src) # tokenを位置符号ベクトルを足してユニークにする\n",
        "        output = self.transformer_encoder(src, src_mask) # mask shape (bptt, bptt)\n",
        "        output = self.decoder(output)\n",
        "        return output # (bptt, batch_size, ntoken)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz2unNUujeuL"
      },
      "source": [
        "``PositionalEncoding`` module injects some information about the\n",
        "relative or absolute position of the tokens in the sequence. The\n",
        "positional encodings have the same dimension as the embeddings so that\n",
        "the two can be summed. Here, we use ``sine`` and ``cosine`` functions of\n",
        "different frequencies.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "2gh3-9yKjeuL"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # pytorchのブロードキャストを使用してバッチサイズを1にして計算される\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD-LQzR8jeuM"
      },
      "source": [
        "Load and batch data\n",
        "-------------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpuJSoyOjeuM"
      },
      "source": [
        "This tutorial uses ``torchtext`` to generate Wikitext-2 dataset. The\n",
        "vocab object is built based on the train dataset and is used to numericalize\n",
        "tokens into tensors. Starting from sequential data, the ``batchify()``\n",
        "function arranges the dataset into columns, trimming off any tokens remaining\n",
        "after the data has been divided into batches of size ``batch_size``.\n",
        "For instance, with the alphabet as the sequence (total length of 26)\n",
        "and a batch size of 4, we would divide the alphabet into 4 sequences of\n",
        "length 6:\n",
        "\n",
        "\\begin{align}\\begin{bmatrix}\n",
        "  \\text{A} & \\text{B} & \\text{C} & \\ldots & \\text{X} & \\text{Y} & \\text{Z}\n",
        "  \\end{bmatrix}\n",
        "  \\Rightarrow\n",
        "  \\begin{bmatrix}\n",
        "  \\begin{bmatrix}\\text{A} \\\\ \\text{B} \\\\ \\text{C} \\\\ \\text{D} \\\\ \\text{E} \\\\ \\text{F}\\end{bmatrix} &\n",
        "  \\begin{bmatrix}\\text{G} \\\\ \\text{H} \\\\ \\text{I} \\\\ \\text{J} \\\\ \\text{K} \\\\ \\text{L}\\end{bmatrix} &\n",
        "  \\begin{bmatrix}\\text{M} \\\\ \\text{N} \\\\ \\text{O} \\\\ \\text{P} \\\\ \\text{Q} \\\\ \\text{R}\\end{bmatrix} &\n",
        "  \\begin{bmatrix}\\text{S} \\\\ \\text{T} \\\\ \\text{U} \\\\ \\text{V} \\\\ \\text{W} \\\\ \\text{X}\\end{bmatrix}\n",
        "  \\end{bmatrix}\\end{align}\n",
        "\n",
        "These columns are treated as independent by the model, which means that\n",
        "the dependence of ``G`` and ``F`` can not be learned, but allows more\n",
        "efficient batch processing.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "AN7Br1qRjeuM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import requests\n",
        "from collections import Counter\n",
        "\n",
        "# データを直接ダウンロード（torchtextを使わずにGitHubから取得）\n",
        "def download_wikitext2(directory=\"data\"):\n",
        "    if not os.path.exists(directory): os.makedirs(directory)\n",
        "    urls = {\n",
        "        \"train\": \"https://raw.githubusercontent.com/pytorch/examples/main/word_language_model/data/wikitext-2/train.txt\",\n",
        "        \"valid\": \"https://raw.githubusercontent.com/pytorch/examples/main/word_language_model/data/wikitext-2/valid.txt\",\n",
        "        \"test\": \"https://raw.githubusercontent.com/pytorch/examples/main/word_language_model/data/wikitext-2/test.txt\"\n",
        "    }\n",
        "    paths = {split: os.path.join(directory, f\"{split}.txt\") for split in urls}\n",
        "    for split, url in urls.items():\n",
        "        if not os.path.exists(paths[split]):\n",
        "            with open(paths[split], \"w\", encoding=\"utf-8\") as f: f.write(requests.get(url).text)\n",
        "    return paths\n",
        "\n",
        "# テキストを数値(ID)に変換する準備\n",
        "def get_data_and_vocab(paths):\n",
        "    def tokenize(text): return text.lower().split()\n",
        "    counter = Counter()\n",
        "    for path in paths.values():\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "              counter.update(tokenize(line))\n",
        "\n",
        "    word_to_id = {\"<unk>\": 0, \"<eos>\": 1}\n",
        "    for word, _ in counter.most_common():\n",
        "        if word not in word_to_id: word_to_id[word] = len(word_to_id)\n",
        "\n",
        "    def process_file(path):\n",
        "        ids = []\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                tokens = tokenize(line)\n",
        "                if tokens:\n",
        "                    # extendは配列の末尾に配列を追加するメソッド: ids.extend([1, 2]) >> [1, 2]\n",
        "                    # dict型のgetメソッドは第一引数にkeyを入れて、第二引数にdefaultを入れる\n",
        "                    ids.extend([word_to_id.get(token, 0) for token in tokens])\n",
        "                    ids.append(1) # <eos>\n",
        "        return torch.tensor(ids, dtype=torch.long)\n",
        "\n",
        "    return process_file(paths[\"train\"]), process_file(paths[\"valid\"]), process_file(paths[\"test\"]), word_to_id\n",
        "\n",
        "# 実行\n",
        "paths = download_wikitext2()\n",
        "train_raw, val_raw, test_raw, word_to_id = get_data_and_vocab(paths)\n",
        "ntokens = len(word_to_id) # the size of vocabulary\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def batchify(data, bsz):\n",
        "    # Divide the dataset into bsz parts.\n",
        "    nbatch = data.size(0) // bsz\n",
        "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
        "    # tensor.narrow()\n",
        "    # - 第一引数: 次元, 今回は0次元方向を対象にしている\n",
        "    # - 第二引数: 開始位置, 今回は0番目開始\n",
        "    # - 第三引数: 長さ, 今回はbszでvocab_sizeを割り切れる分だけ\n",
        "    # 割り切れなかったあまりを切り捨てることでviewで変形できるようにしている\n",
        "    data = data.narrow(0, 0, nbatch * bsz)\n",
        "    # Evenly divide the data across the bsz batches.\n",
        "    # batch first False用に転置\n",
        "    # contiguous()はメモリの配置を連続にする関数\n",
        "    # 転置は見方を変えるだけなのでメモリ上のデータ配置も連続になるようにしている\n",
        "    data = data.view(bsz, -1).t().contiguous()\n",
        "    return data.to(device)\n",
        "\n",
        "batch_size = 20\n",
        "eval_batch_size = 10\n",
        "train_data = batchify(train_raw, batch_size)\n",
        "val_data = batchify(val_raw, eval_batch_size)\n",
        "test_data = batchify(test_raw, eval_batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOdotnf9jeuM"
      },
      "source": [
        "Functions to generate input and target sequence\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hWZtL1vjeuM"
      },
      "source": [
        "``get_batch()`` function generates the input and target sequence for\n",
        "the transformer model. It subdivides the source data into chunks of\n",
        "length ``bptt``. For the language modeling task, the model needs the\n",
        "following words as ``Target``. For example, with a ``bptt`` value of 2,\n",
        "we’d get the following two Variables for ``i`` = 0:\n",
        "\n",
        "![](../_static/img/transformer_input_target.png)\n",
        "\n",
        "\n",
        "It should be noted that the chunks are along dimension 0, consistent\n",
        "with the ``S`` dimension in the Transformer model. The batch dimension\n",
        "``N`` is along dimension 1.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "aw_stXv-jeuM"
      },
      "outputs": [],
      "source": [
        "bptt = 35 # Backpropagation Through Time\n",
        "def get_batch(source, i):\n",
        "    seq_len = min(bptt, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    # reshapeはメモリ上のデータが揃っていなくてもtensorのshapeを\n",
        "    # 変換してくれる関数\n",
        "    # viewはデータが揃っていないとエラーになる\n",
        "    # sliceを使用しているのでデータが揃っていない可能性がある\n",
        "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
        "    return data, target"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_data, log_target = get_batch(train_data, 1)\n",
        "print(log_data.shape)\n",
        "print(log_target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0d8XFxm7g0T",
        "outputId": "52802507-cd28-4df5-cd54-3fde63535c1e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([35, 20])\n",
            "torch.Size([700])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SWgccOujeuM"
      },
      "source": [
        "Initiate an instance\n",
        "--------------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSM2uKQIjeuM"
      },
      "source": [
        "The model is set up with the hyperparameter below. The vocab size is\n",
        "equal to the length of the vocab object.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFWgMS3tjeuM",
        "outputId": "47aad943-7c96-4fcf-c92f-8db9c285ffc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3255949110.py:14: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n"
          ]
        }
      ],
      "source": [
        "emsize = 200 # embedding dimension\n",
        "nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2 # the number of heads in the multiheadattention models\n",
        "dropout = 0.2 # the dropout value\n",
        "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRg_o8ORjeuM"
      },
      "source": [
        "Run the model\n",
        "-------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcQ3AhJBjeuN"
      },
      "source": [
        "`CrossEntropyLoss <https://pytorch.org/docs/master/nn.html?highlight=crossentropyloss#torch.nn.CrossEntropyLoss>`__\n",
        "is applied to track the loss and\n",
        "`SGD <https://pytorch.org/docs/master/optim.html?highlight=sgd#torch.optim.SGD>`__\n",
        "implements stochastic gradient descent method as the optimizer. The initial\n",
        "learning rate is set to 5.0. `StepLR <https://pytorch.org/docs/master/optim.html?highlight=steplr#torch.optim.lr_scheduler.StepLR>`__ is\n",
        "applied to adjust the learn rate through epochs. During the\n",
        "training, we use\n",
        "`nn.utils.clip_grad_norm\\_ <https://pytorch.org/docs/master/nn.html?highlight=nn%20utils%20clip_grad_norm#torch.nn.utils.clip_grad_norm_>`__\n",
        "function to scale all the gradient together to prevent exploding.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.optim.lr_scheduler.StepLR()\n",
        "学習率を段階的に調整していくスケジューラー\n",
        "- 第一引数: 対象となるoptimizer\n",
        "- 第二引数: 学習率を変更するステップ（scheduler.step()で1カウント）\n",
        "- 第三引数: 1ステップでどのくらい学習率を変化させるかの割合\n",
        "\n",
        "### get_last_lr()とは？\n",
        "スケジューラーが最後に計算した学習率を取得する。"
      ],
      "metadata": {
        "id": "RPp4nbR21ZV0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## nn.CrossEntropyLoss()\n",
        "- 第一引数: モデルの予測を受けとる。(N, C)の形になる。\n",
        "- 第二引数: 正解を受け取る。(N,)の形になる。\n",
        "`CrossEntropyLoss()`は内部で正解のデータのインデックスを使用して、モデルが予測したスコアを使用してそれが正解とどれだけ離れているのかを計算する。"
      ],
      "metadata": {
        "id": "GYpmqmsZKVvH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.nn.utils.clip_grad_norm_()\n",
        "勾配爆発を防ぐための勾配クリップ。\n",
        "- 第一引数: モデルの重みが全部入っているリストを渡す。\n",
        "- 第二引数: 勾配の上限。"
      ],
      "metadata": {
        "id": "DopFUC0TFKOT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "lwYd2D3SjeuN"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 5.0 # learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
        "\n",
        "import time\n",
        "def train():\n",
        "    model.train() # Turn on the train mode\n",
        "    total_loss = 0.\n",
        "    start_time = time.time() # 1970年1月1日からの経過秒数を返す\n",
        "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
        "        data, targets = get_batch(train_data, i)\n",
        "        optimizer.zero_grad()\n",
        "        if data.size(0) != bptt:\n",
        "            src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
        "        output = model(data, src_mask)\n",
        "        loss = criterion(output.view(-1, ntokens), targets)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        log_interval = 200\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            elapsed = time.time() - start_time # elapsed->経過した\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
        "                  'lr {:02.2f} | ms/batch {:5.2f} | '\n",
        "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
        "                    epoch, batch, len(train_data) // bptt, scheduler.get_last_lr()[0],\n",
        "                    elapsed * 1000 / log_interval,\n",
        "                    cur_loss, math.exp(cur_loss))) # PPLについてはNLP100本ノック93で済み\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(eval_model, data_source):\n",
        "    eval_model.eval() # Turn on the evaluation mode\n",
        "    total_loss = 0.\n",
        "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, data_source.size(0) - 1, bptt):\n",
        "            data, targets = get_batch(data_source, i)\n",
        "            if data.size(0) != bptt:\n",
        "                src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
        "            output = eval_model(data, src_mask)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
        "    return total_loss / (len(data_source) - 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuhgjYK0jeuN"
      },
      "source": [
        "Loop over epochs. Save the model if the validation loss is the best\n",
        "we've seen so far. Adjust the learning rate after each epoch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnDVN3EWjeuN",
        "outputId": "77cfac88-a016-4c33-d347-01a560a486aa"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |   200/ 2965 batches | lr 5.00 | ms/batch 564.01 | loss  7.99 | ppl  2955.82\n",
            "| epoch   1 |   400/ 2965 batches | lr 5.00 | ms/batch 552.17 | loss  6.85 | ppl   947.32\n",
            "| epoch   1 |   600/ 2965 batches | lr 5.00 | ms/batch 558.05 | loss  6.42 | ppl   615.46\n",
            "| epoch   1 |   800/ 2965 batches | lr 5.00 | ms/batch 548.48 | loss  6.29 | ppl   541.02\n"
          ]
        }
      ],
      "source": [
        "best_val_loss = float(\"inf\")\n",
        "epochs = 3 # The number of epochs\n",
        "best_model = None\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train()\n",
        "    val_loss = evaluate(model, val_data)\n",
        "    print('-' * 89)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
        "          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
        "                                     val_loss, math.exp(val_loss)))\n",
        "    print('-' * 89)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_model = model\n",
        "\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzSMQMHqjeuN"
      },
      "source": [
        "Evaluate the model with the test dataset\n",
        "-------------------------------------\n",
        "\n",
        "Apply the best model to check the result with the test dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Xa4nAg9jeuN"
      },
      "outputs": [],
      "source": [
        "test_loss = evaluate(best_model, test_data)\n",
        "print('=' * 89)\n",
        "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
        "    test_loss, math.exp(test_loss)))\n",
        "print('=' * 89)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}